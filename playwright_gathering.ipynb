{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5afa0f3-1ad1-402e-9b17-d76e5ab125f8",
   "metadata": {},
   "source": [
    "# Zillow Word Clouds\n",
    "### Or, how Zillow listing language changes in different LA neighborhoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3bbb0d24-03c9-4d8e-85d8-1342722d65e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Dependencies installed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Install required dependencies\n",
    "# Only need to run this cell once\n",
    "\n",
    "!pip install --quiet playwright pandas matplotlib seaborn wordcloud nltk\n",
    "!playwright install  # This installs browser binaries needed by Playwright\n",
    "\n",
    "# If you're running in Google Colab, you might need:\n",
    "# !apt-get update\n",
    "# !apt-get install -y xvfb\n",
    "# !pip install playwright pandas matplotlib seaborn wordcloud nltk\n",
    "# !playwright install\n",
    "\n",
    "print(\"Dependencies installed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4a83a5a-f299-40bb-b18e-d99eb0c05232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports of various libraries\n",
    "\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import asyncio\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from playwright.async_api import async_playwright, expect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17e49e70-f2e7-4a8e-8ad1-67a361953072",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/ryanbrooks/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/ryanbrooks/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up data directory\n",
    "os.makedirs('data/', exist_ok=True)\n",
    "\n",
    "# Download NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "713e49ac-659b-420e-bf93-f404f9e0eabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom real estate stopwords to filter out common terms\n",
    "real_estate_stopwords = set([\n",
    "    'home', 'property', 'house', 'listing', 'features', 'includes',\n",
    "    'located', 'offers', 'contact', 'information', 'price', 'sale',\n",
    "    'bedroom', 'bathroom', 'bath', 'bed', 'sq', 'ft', 'square', 'feet',\n",
    "    'year', 'built', 'call', 'today', 'agent', 'new', 'view', 'tour'\n",
    "])\n",
    "\n",
    "# Target neighborhoods in LA\n",
    "neighborhoods = [\n",
    "    \"Beverly Hills\",\n",
    "    \"Boyle Heights\",\n",
    "    \"Leimert Park\", \n",
    "    \"Sherman Oaks\",\n",
    "    \"Koreatown\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39a86285-971c-4e7f-abef-9b390e1c22b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starts an automated browser and opens a new window\n",
    "\n",
    "async def open_browser(headless=False):\n",
    "    playwright = await async_playwright().start()\n",
    "    \n",
    "    # Random user agent to appear more human\n",
    "    user_agent = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/96.0.4664.110 Safari/537.36'\n",
    "    \n",
    "    # Launch browser with stealth settings\n",
    "    browser = await playwright.chromium.launch(\n",
    "        headless=headless,\n",
    "        slow_mo=50\n",
    "    )\n",
    "    \n",
    "    # Create context with custom settings to avoid detection\n",
    "    context = await browser.new_context(\n",
    "        user_agent=user_agent,\n",
    "        viewport={'width': 1280, 'height': 800},\n",
    "        device_scale_factor=1,\n",
    "        is_mobile=False\n",
    "    )\n",
    "    \n",
    "    # Create a new page\n",
    "    page = await context.new_page()\n",
    "    \n",
    "    return browser, page, playwright"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3c550bc-bceb-4179-ad2b-e7c9c71c5b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for a specific neighborhood on Zillow\n",
    "\n",
    "async def search_neighborhood(page, neighborhood):\n",
    "    url = 'https://zillow.com'\n",
    "    await page.goto(url)\n",
    "    await asyncio.sleep(2)\n",
    "    \n",
    "    # Find search box using aria-label attribute\n",
    "    search_box = page.get_by_role('textbox', name='Search')\n",
    "    await search_box.fill(f\"{neighborhood}, Los Angeles, CA\")\n",
    "    await asyncio.sleep(1)\n",
    "    \n",
    "    # Wait for suggestions and click the first one\n",
    "    await expect(page.get_by_role('option').first).to_be_visible()\n",
    "    await page.get_by_role('option').first.click()\n",
    "    await asyncio.sleep(2)\n",
    "    \n",
    "    # Select \"For Sale\" if prompted\n",
    "    for_sale_button = page.get_by_role('button', name='For Sale')\n",
    "    if await for_sale_button.is_visible():\n",
    "        await for_sale_button.click()\n",
    "        await asyncio.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77856fb5-c6d9-4632-8050-ffd8993ef240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract all listing descriptions from the current page\n",
    "\n",
    "async def get_descriptions(page):\n",
    "    descriptions = []\n",
    "    prices = []\n",
    "    addresses = []\n",
    "    \n",
    "    # Load all cards by scrolling\n",
    "    N = 0\n",
    "    while True:\n",
    "        # Find all property cards\n",
    "        cards = await page.locator('[data-test=\"property-card\"]').all()\n",
    "        if not cards:\n",
    "            break\n",
    "            \n",
    "        # Scroll to the last visible card\n",
    "        last_card = cards[-1]\n",
    "        await last_card.scroll_into_view_if_needed()\n",
    "        \n",
    "        # Check if we've loaded all cards\n",
    "        N_cards = len(cards)\n",
    "        if N_cards == N:\n",
    "            break\n",
    "        N = N_cards\n",
    "        await asyncio.sleep(2)\n",
    "    \n",
    "    # Extract information from each card\n",
    "    for card in await page.locator('[data-test=\"property-card\"]').all():\n",
    "        # Get price\n",
    "        price_elem = card.locator('[data-test=\"property-card-price\"]')\n",
    "        if await price_elem.count() > 0:\n",
    "            price = await price_elem.text_content()\n",
    "            prices.append(price)\n",
    "        else:\n",
    "            prices.append(\"N/A\")\n",
    "            \n",
    "        # Get address\n",
    "        address_elem = card.locator('[data-test=\"property-card-addr\"]')\n",
    "        if await address_elem.count() > 0:\n",
    "            address = await address_elem.text_content()\n",
    "            addresses.append(address)\n",
    "        else:\n",
    "            addresses.append(\"N/A\")\n",
    "            \n",
    "        # Click card to view description\n",
    "        await card.click()\n",
    "        await asyncio.sleep(2)\n",
    "        \n",
    "        # Extract description from the detail page\n",
    "        desc_elem = page.locator('.ds-overview-section')\n",
    "        if await desc_elem.count() > 0:\n",
    "            description = await desc_elem.text_content()\n",
    "            descriptions.append(description)\n",
    "        else:\n",
    "            descriptions.append(\"\")\n",
    "            \n",
    "        # Go back to results\n",
    "        await page.go_back()\n",
    "        await asyncio.sleep(1)\n",
    "    \n",
    "    return {\n",
    "        'prices': prices,\n",
    "        'addresses': addresses,\n",
    "        'descriptions': descriptions\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d74908d6-691d-4203-b6e6-e0c047fdab05",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def scrape_neighborhood_data(neighborhood):\n",
    "    \"\"\"\n",
    "    Scrape listing data for a specific neighborhood\n",
    "    \"\"\"\n",
    "    browser, page, playwright = await open_browser()\n",
    "    \n",
    "    try:\n",
    "        print(f\"Searching for {neighborhood}...\")\n",
    "        await search_neighborhood(page, neighborhood)\n",
    "        \n",
    "        print(f\"Extracting listings for {neighborhood}...\")\n",
    "        data = await get_descriptions(page)\n",
    "        \n",
    "        # Save the raw HTML\n",
    "        html_content = await page.content()\n",
    "        with open(f'data/{neighborhood.replace(\" \", \"_\")}_listings.html', 'w', encoding='utf-8') as f:\n",
    "            f.write(html_content)\n",
    "            \n",
    "        # Create dataframe and save to CSV\n",
    "        df = pd.DataFrame({\n",
    "            'neighborhood': [neighborhood] * len(data['descriptions']),\n",
    "            'price': data['prices'],\n",
    "            'address': data['addresses'],\n",
    "            'description': data['descriptions']\n",
    "        })\n",
    "        \n",
    "        df.to_csv(f'data/{neighborhood.replace(\" \", \"_\")}_listings.csv', index=False)\n",
    "        print(f\"Saved {len(df)} listings for {neighborhood}\")\n",
    "        \n",
    "        return df\n",
    "        \n",
    "    finally:\n",
    "        await browser.close()\n",
    "        await playwright.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52689556-088d-41a2-993c-3b079f66bf22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_word_cloud(neighborhood, description_text):\n",
    "    \"\"\"\n",
    "    Generate word cloud for neighborhood listings\n",
    "    \"\"\"\n",
    "    # Combine all descriptions\n",
    "    all_text = ' '.join(description_text)\n",
    "    \n",
    "    # Tokenize and clean\n",
    "    stop_words = set(stopwords.words('english')).union(real_estate_stopwords)\n",
    "    tokens = [w.lower() for w in word_tokenize(all_text) \n",
    "              if w.isalpha() and w.lower() not in stop_words and len(w) > 2]\n",
    "    \n",
    "    # Count word frequencies\n",
    "    word_freq = Counter(tokens)\n",
    "    \n",
    "    # Generate word cloud\n",
    "    wordcloud = WordCloud(\n",
    "        width=800, \n",
    "        height=400,\n",
    "        background_color='white',\n",
    "        max_words=100,\n",
    "        contour_width=1\n",
    "    ).generate_from_frequencies(word_freq)\n",
    "    \n",
    "    # Plot and save\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.title(f'Most Common Terms in {neighborhood} Listings')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'data/{neighborhood.replace(\" \", \"_\")}_wordcloud.png', dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "    return word_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a3a0dd9-8dcd-428d-8456-bc9c21caa599",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_comparison_charts(all_data):\n",
    "    \"\"\"\n",
    "    Create comparison charts across neighborhoods\n",
    "    \"\"\"\n",
    "    # Prepare data for charts\n",
    "    all_neighborhoods_data = {}\n",
    "    avg_prices = {}\n",
    "    word_counts = {}\n",
    "    \n",
    "    for neighborhood, group in all_data.groupby('neighborhood'):\n",
    "        # Process text for analysis\n",
    "        all_text = ' '.join(group['description'].dropna())\n",
    "        stop_words = set(stopwords.words('english')).union(real_estate_stopwords)\n",
    "        tokens = [w.lower() for w in word_tokenize(all_text) \n",
    "                  if w.isalpha() and w.lower() not in stop_words and len(w) > 2]\n",
    "        \n",
    "        # Count word frequencies\n",
    "        word_freq = Counter(tokens)\n",
    "        all_neighborhoods_data[neighborhood] = word_freq\n",
    "        \n",
    "        # Calculate average price\n",
    "        prices = group['price'].str.replace('$', '').str.replace(',', '').astype(float)\n",
    "        avg_prices[neighborhood] = prices.mean()\n",
    "        \n",
    "        # Calculate average word count\n",
    "        word_counts[neighborhood] = len(all_text.split()) / len(group)\n",
    "    \n",
    "    # Chart 1: Top terms comparison\n",
    "    # Get common terms across all neighborhoods\n",
    "    all_terms = set()\n",
    "    for neighborhood, word_freq in all_neighborhoods_data.items():\n",
    "        all_terms.update(word_freq.keys())\n",
    "    \n",
    "    # Find most common terms overall\n",
    "    combined_freq = Counter()\n",
    "    for word_freq in all_neighborhoods_data.values():\n",
    "        combined_freq.update(word_freq)\n",
    "    \n",
    "    top_terms = [term for term, _ in combined_freq.most_common(10)]\n",
    "    \n",
    "    # Create DataFrame for plotting\n",
    "    chart_data = []\n",
    "    for term in top_terms:\n",
    "        for neighborhood in all_neighborhoods_data.keys():\n",
    "            freq = all_neighborhoods_data[neighborhood].get(term, 0)\n",
    "            chart_data.append({\n",
    "                'Term': term,\n",
    "                'Neighborhood': neighborhood,\n",
    "                'Frequency': freq\n",
    "            })\n",
    "    \n",
    "    chart_df = pd.DataFrame(chart_data)\n",
    "    \n",
    "    # Plot bar chart\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    chart = sns.barplot(x='Frequency', y='Term', hue='Neighborhood', data=chart_df)\n",
    "    plt.title('Top 10 Terms by Neighborhood')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('data/top_terms_comparison.png', dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "    # Chart 2: Price vs. Word Count\n",
    "    price_data = pd.DataFrame({\n",
    "        'Neighborhood': list(avg_prices.keys()),\n",
    "        'Average Price': [avg_prices[n] for n in avg_prices.keys()],\n",
    "        'Average Word Count': [word_counts[n] for n in avg_prices.keys()]\n",
    "    })\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.scatterplot(x='Average Price', y='Average Word Count', data=price_data)\n",
    "    \n",
    "    # Add neighborhood labels to points\n",
    "    for i, row in price_data.iterrows():\n",
    "        plt.text(row['Average Price'], row['Average Word Count'], row['Neighborhood'])\n",
    "    \n",
    "    plt.title('Relationship Between Listing Price and Description Length')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('data/price_vs_wordcount.png', dpi=300)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a67354-e0d9-4af3-813e-411142e90345",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main():\n",
    "    # Collect data for each neighborhood\n",
    "    all_dfs = []\n",
    "    \n",
    "    for neighborhood in neighborhoods:\n",
    "        df = await scrape_neighborhood_data(neighborhood)\n",
    "        all_dfs.append(df)\n",
    "        \n",
    "        # Generate word cloud for each neighborhood\n",
    "        create_word_cloud(neighborhood, df['description'])\n",
    "        \n",
    "        # Pause between neighborhoods to avoid detection\n",
    "        await asyncio.sleep(5)\n",
    "    \n",
    "    # Combine all data\n",
    "    all_data = pd.concat(all_dfs)\n",
    "    all_data.to_csv('data/all_neighborhoods.csv', index=False)\n",
    "    \n",
    "    # Create comparison charts\n",
    "    create_comparison_charts(all_data)\n",
    "    \n",
    "    print(\"Analysis complete! Check the data directory for results.\")\n",
    "\n",
    "# Run the main function\n",
    "await main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
